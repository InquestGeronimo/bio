[Hugging Face ðŸ¤— Profile](https://huggingface.co/zeroshot): includes full list of models and datasets.

[NLP Index](https://index.quantumstat.com/): public search engine for searching top GitHub repos and Arxiv papers in NLP.

# CODE

| Example     |      Description      |
|----------|-------------|
| [CypherTune]([https://github.com/InquestGeronimo/horizon-takeoff](https://github.com/InquestGeronimo/cyphertune) | A simple LLM fine-tuning library for the text-2-Cypher task. |
| [Horizon Takeoff](https://github.com/InquestGeronimo/horizon-takeoff) | Library for automating the deployment of TitanML's Takeoff Server for LLM inference on AWS. |
| [WhisperYT](https://github.com/InquestGeronimo/whisperyt) | Python client for Gladia's ASR API for YouTube transcription using Whisper. |
| [Hacker News Python Client](https://github.com/InquestGeronimo/hacker-news-client) | A simple Python client to interact with the official Hacker News Firebase API. |
| [AWS Sagemaker Integration](https://github.com/neuralmagic/deepsparse/tree/main/examples/aws-sagemaker/)  | How to deploy a DeepSparse inference server on SageMaker. |
| [AWS Serverless Integration](https://github.com/neuralmagic/deepsparse/tree/main/examples/aws-serverless/)  | How to deploy a DeepSparse pipeline for batch or real-time inference on select serverless services. |
| [Amazon EKS Cluster Integration Using the do-framework](https://github.com/neuralmagic/aws-do-eks) | Deploying an inference engine on EKS Cluster |
| [Benchmark UI - DigitalOcean Deployment](https://github.com/neuralmagic/deepsparse/tree/main/examples/benchmark-ui/)  | How to deploy a gradio UI for benchmarking SparseZoo models on a DigitalOcean instance or local machine.  |
| [ChatGPT Cheat Sheet](https://github.com/neuralmagic/deepsparse/tree/main/examples/chatgpt-cheat-sheet/)  | User guide for prompting ChatGPT segmented by use-case.  |
| [SparseServer.UI](https://github.com/neuralmagic/deepsparse/tree/main/examples/sparseserver-ui/)  | A Streamlit app for deploying the DeepSparse Server to compare the latency and accuracy of sparse BERT models. |
| [Google Cloud Run Integration](https://github.com/neuralmagic/deepsparse/tree/main/examples/google-cloud-run/) | How to deploy the DeepSparse Server on Cloud Run. |
| [AWS Marketplace](https://github.com/neuralmagic/deepsparse/tree/main/examples/aws-marketplace/)  | How to launch a DeepSparse integrated instance via the AWS Marketplace. |
| [DigitalOcean Marketplace](https://github.com/neuralmagic/deepsparse/tree/main/examples/do-marketplace/)  | How to launch a DeepSparse integrated instance via the DigitalOcean Marketplace. |
| [GCP Marketplace](https://github.com/neuralmagic/deepsparse/tree/main/examples/gcp-marketplace/) | How to launch a DeepSparse integrated instance on the Google Cloud Marketplace. |
| [Azure VM](https://github.com/neuralmagic/deepsparse/tree/main/examples/azure-vm/)  | How to launch a DeepSparse image in an Azure virtual machine. |

# MODELS
[bge-small-en-v1.5-quant](https://huggingface.co/neuralmagic/bge-small-en-v1.5-quant)

[bge-base-en-v1.5-quant](https://huggingface.co/neuralmagic/bge-base-en-v1.5-quant)

[bge-large-en-v1.5-quant](https://huggingface.co/neuralmagic/bge-large-en-v1.5-quant)

[bge-small-en-v1.5-sparse](https://huggingface.co/neuralmagic/bge-small-en-v1.5-sparse)

[bge-base-en-v1.5-sparse](https://huggingface.co/neuralmagic/bge-base-en-v1.5-sparse)

[bge-large-en-v1.5-sparse](https://huggingface.co/neuralmagic/bge-large-en-v1.5-sparse)

# DATASETS
[Twitter Financial News Sentiment Dataset](https://huggingface.co/datasets/zeroshot/twitter-financial-news-sentiment)

[Twitter Financial News Topic Dataset](https://huggingface.co/datasets/zeroshot/twitter-financial-news-topic)

[Bio Arxiv](https://huggingface.co/datasets/zeroshot/arxiv-biology)

# BLOGS
[OpenAI integration](https://neuralmagic.com/blog/integrating-deepsparse-with-openais-api-for-fast-local-llms/)

[Scaling CPU Inference on AWS EKS](https://neuralmagic.com/blog/scaling-cpu-inference-on-aws-eks-with-deepsparse/)

[AWS Serverless](https://neuralmagic.com/blog/deploy-serverless-machine-learning-inference-on-aws-with-deepsparse/)

[DigitalOcean CPU Inference w/ Gradio](https://neuralmagic.com/blog/how-to-achieve-up-to-3x-ai-speedup-on-digitaloceans-premium-cpus/)

[Sparse BioBERT](https://neuralmagic.com/blog/revolutionizing-biology-research-with-lightning-fast-nlp-introducing-sparse-biobert/)

[Year in Review](https://neuralmagic.com/blog/2022-year-in-review-at-neural-magic/)

[ðŸ¤— Inference Endpoints](https://neuralmagic.com/blog/accelerate-hugging-face-inference-endpoints-with-deepsparse/)

[Financial Tweet Classification of Real-Time Stream](https://neuralmagic.com/blog/classifying-finance-tweets-in-real-time-with-sparse-transformers/)

[Zero-shot learning](https://neuralmagic.com/blog/faster-zero-shot-learning-with-sparsity/)

[AWS Sagemaker](https://neuralmagic.com/blog/deepsparse-engine-aws-sagemaker/)

# NOTEBOOKS
[Sparsifying BGE-Small Embeddings Model](https://colab.research.google.com/github/neuralmagic/examples/blob/main/notebooks/sparsify-bge-small/Sparsifying_BGE_Small.ipynb)

[Using Sparsify One-Shot for Sparsifying MiniLM for a Semantic Search Use-Case](https://colab.research.google.com/github/neuralmagic/examples/blob/main/notebooks/sparsify-sentence-embeddings/Sparsify_One-Shot.ipynb)

[Sparse Transfer NLP Models from Hugging Face Using SparseML!](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqblg0YjlGNUFwZ1pRRzJhd0RwWndQRWV4ZUF2Z3xBQ3Jtc0trV21HVkhwZjNxQlMtY2xjVHRrMG9obzlybXFnNlNFQnJBeUlqZVR0WWY0aFp4YkczeEU5VnJ5Vzc5YVk1THBobjkxTlNLSDdhTHJhYkxvSENHWjNmYmptZlZnclRUS3M4T2NtZjVKclYtVjhBY0Z0TQ&q=https%3A%2F%2Fcolab.research.google.com%2Fdrive%2F1I5ez6ZpdT0K-yo7l9AXrrJ7tIFoEP8Jv&v=ltdKqiB7FFU)

[Optimum DeepSparse Pipelines](https://github.com/neuralmagic/examples/blob/main/notebooks/optimum-export/optimum-pipelines.ipynb)

# VIDEOS

[Sparse Transferring Hugging Face Models With SparseML](https://www.youtube.com/watch?v=ltdKqiB7FFU)
